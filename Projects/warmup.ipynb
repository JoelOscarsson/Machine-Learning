{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recommender system\n",
    "\n",
    "Whether is is watching Youtube, ordering food online, buy books online, listening on Spotify, using LinkedIn. You\n",
    "get constant recommendations for new videoclips, what to eat and much more. What's behind all this is a recommender system."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Warmup\n",
    "Creating a easy recommender system for movies with KNN. \n",
    "\n",
    "100.000 dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from scipy.sparse import csr_matrix\n",
    "# k-nearest\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "## Efficent way to match two strings together\n",
    "    # What it does is:\n",
    "        # if we have spelling mistakes, capitalizing or forget to add spaces it can mash movies\n",
    "        # it can select the index\n",
    "from fuzzywuzzy import process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies = (\"/Users/joeloscarsson/Documents/www/Machine-Learning/Projects/data2/movies.csv\")\n",
    "ratings = (\"/Users/joeloscarsson/Documents/www/Machine-Learning/Projects/data2/ratings.csv\")\n",
    "\n",
    "df_movies = pd.read_csv(movies, usecols=['movieId', 'title'], dtype={'movieId': 'int32', 'title': 'str'})\n",
    "df_ratings = pd.read_csv(ratings, usecols=['userId', 'movieId', 'rating'], dtype={'userId': 'int32', 'movieId': 'int32', 'rating':'float32'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To be able to convert data to see K-Nearest\n",
    "# Use Spare Matrix\n",
    "# example \n",
    "#          Users\n",
    "#         [4,4,5] A\n",
    "# Movies  [3,3,4] B == Cos A,B) => 0.95 Similar\n",
    "#         [3,2,1] C\n",
    "\n",
    "\n",
    "# Why we use \"rating\" is the same reason we use \"Sales\" in Excercises. So we can get something for y-axis to compare\n",
    "movies_users = df_ratings.pivot(index='movieId', columns='userId', values='rating').fillna(0)\n",
    "# A lot of NaN values because people haven't voted on a movie. We can't process this data so we used .fillna(0)\n",
    "mat_movies_users = csr_matrix(movies_users.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specifying distance between two vectors \n",
    "# Euclidean Distance\n",
    "# Manhattan Distance\n",
    "# Minkowski Distance\n",
    "# Cosine Similarity\n",
    "\n",
    "\n",
    "# Using brute because traverse thru all datapoints in the whole dataset \n",
    "model_knn = NearestNeighbors(metric='cosine', algorithm='brute', n_neighbors= 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>NearestNeighbors(algorithm=&#x27;brute&#x27;, metric=&#x27;cosine&#x27;, n_neighbors=20)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">NearestNeighbors</label><div class=\"sk-toggleable__content\"><pre>NearestNeighbors(algorithm=&#x27;brute&#x27;, metric=&#x27;cosine&#x27;, n_neighbors=20)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "NearestNeighbors(algorithm='brute', metric='cosine', n_neighbors=20)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_knn.fit(mat_movies_users)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Movie Selected:  Toy Story (1995) Index:  0\n",
      "Searching for recommendations......\n",
      "0                                                     NaN\n",
      "2353                                 'night Mother (1986)\n",
      "418                                  Jurassic Park (1993)\n",
      "615                  Independence Day (a.k.a. ID4) (1996)\n",
      "224             Star Wars: Episode IV - A New Hope (1977)\n",
      "314                                   Forrest Gump (1994)\n",
      "322                                 Lion King, The (1994)\n",
      "910     Once Upon a Time in the West (C'era una volta ...\n",
      "546                            Mission: Impossible (1996)\n",
      "963                                           Diva (1981)\n",
      "968                           Arsenic and Old Lace (1944)\n",
      "3189            Rififi (Du rififi chez les hommes) (1955)\n",
      "506                                        Aladdin (1992)\n",
      "123                                      Apollo 13 (1995)\n",
      "257                                   Pulp Fiction (1994)\n",
      "897                 Cheech and Chong's Up in Smoke (1978)\n",
      "815            Willy Wonka & the Chocolate Factory (1971)\n",
      "1182                                          Fall (1997)\n",
      "31              Twelve Monkeys (a.k.a. 12 Monkeys) (1995)\n",
      "277                      Shawshank Redemption, The (1994)\n",
      "Name: title, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Recommender (movie_name) => List of Movies recommended\n",
    "\n",
    "def recommender(movie_name, data, model, n_recommendations):\n",
    "    model.fit(data)\n",
    "    # Extracting one movie fuzzy has selected for us\n",
    "    # so i choose 'title' from df_movies and i want to match movie names in the title column\n",
    "    # We specify index 2 because we have a tuple\n",
    "    idx=process.extractOne(movie_name, df_movies['title'])[2] \n",
    "    # print(idx)\n",
    "    print('Movie Selected: ', df_movies['title'][idx], 'Index: ', idx)\n",
    "    print('Searching for recommendations......')\n",
    "    # We specified the index from one movie to find similar movies\n",
    "        # We got the movie index from what we extracted with help of fuzzywuzzy\n",
    "    distances, indices=model.kneighbors(data[idx], n_neighbors=n_recommendations)\n",
    "\n",
    "    # What we get out is the closest similarities but outcommented this and created a for loop\n",
    "    # print(distances, indices)\n",
    "\n",
    "    # We want all indices close to 100%\n",
    "    # We dont want to compare toy story to toy story therefor i!=idx\n",
    "    for i in indices:\n",
    "        print(df_movies['title'][i].where(i!=idx))\n",
    "\n",
    "recommender('toy story', mat_movies_users, model_knn,20)\n",
    "\n",
    "# gives me the matched sequence it got (90)\n",
    "# gives me the index of the particular movie in the dataset(0)\n",
    "# recommender('toy story')\n",
    " # Output ('Toy Story (1995)', 90, 0)\n",
    "\n",
    " # Based on the user ratings we got movies similair to 'toy story'. Doesn't have to be similar movies though\n",
    " # It is possibly to sort based on genres aswell"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Machine-Learning-I2BFtoY6",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a90a544548112fd3fa9316a2ef2cee63f5075b890673fd358010aa684e625a09"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
