{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scikit-Learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TV</th>\n",
       "      <th>Radio</th>\n",
       "      <th>Newspaper</th>\n",
       "      <th>Sales</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>230.1</td>\n",
       "      <td>37.8</td>\n",
       "      <td>69.2</td>\n",
       "      <td>22.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>44.5</td>\n",
       "      <td>39.3</td>\n",
       "      <td>45.1</td>\n",
       "      <td>10.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>17.2</td>\n",
       "      <td>45.9</td>\n",
       "      <td>69.3</td>\n",
       "      <td>9.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>151.5</td>\n",
       "      <td>41.3</td>\n",
       "      <td>58.5</td>\n",
       "      <td>18.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>180.8</td>\n",
       "      <td>10.8</td>\n",
       "      <td>58.4</td>\n",
       "      <td>12.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      TV  Radio  Newspaper  Sales\n",
       "1  230.1   37.8       69.2   22.1\n",
       "2   44.5   39.3       45.1   10.4\n",
       "3   17.2   45.9       69.3    9.3\n",
       "4  151.5   41.3       58.5   18.5\n",
       "5  180.8   10.8       58.4   12.9"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "df = pd.read_csv(\"../data/Advertising.csv\", index_col=0)\n",
    "\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200, 3)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "number_of_samples, number_of_features = df.shape[0], df.shape[1]-1 #-1 because sales is label and not a feature\n",
    "\n",
    "number_of_samples, number_of_features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TV</th>\n",
       "      <th>Radio</th>\n",
       "      <th>Newspaper</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>230.1</td>\n",
       "      <td>37.8</td>\n",
       "      <td>69.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>44.5</td>\n",
       "      <td>39.3</td>\n",
       "      <td>45.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>17.2</td>\n",
       "      <td>45.9</td>\n",
       "      <td>69.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>151.5</td>\n",
       "      <td>41.3</td>\n",
       "      <td>58.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>180.8</td>\n",
       "      <td>10.8</td>\n",
       "      <td>58.4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      TV  Radio  Newspaper\n",
       "1  230.1   37.8       69.2\n",
       "2   44.5   39.3       45.1\n",
       "3   17.2   45.9       69.3\n",
       "4  151.5   41.3       58.5\n",
       "5  180.8   10.8       58.4"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X, y = df.drop('Sales', axis='columns'), df['Sales']\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    22.1\n",
       "2    10.4\n",
       "3     9.3\n",
       "4    18.5\n",
       "5    12.9\n",
       "Name: Sales, dtype: float64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.head() # Vår label. konvention inom ml community att använda X och y."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sklearn - steps\n",
    "Detta är ett recept som funkar för flera algoritmer\n",
    "\n",
    "Typical steps\n",
    " *   1. train|test split, sometimes train|val|test split if you have large amounts of data\n",
    " *   2. scaling? sometimes required?\n",
    " *   - min-max scaling\n",
    " *   - standardization\n",
    " *   - ...\n",
    " *   - scale the training data, scale test data to the training data --> avoiding data leakage\n",
    " *       # Kan vara skala i statisik, t ex när man transformera till z för att standardisera data\n",
    " *   3. Fit algorithm to training data\n",
    " *       # Träning, alltså weights and biases. (Kan behövas datakraft från olika cloud kluster)\n",
    " *   4. Predict test data\n",
    " *       # Man har sina parametrar sen gör man prediction\n",
    " *   5. Evaluate\n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train|test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((140, 3), (60, 3), (140,), (60,))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.3, random_state=42)\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature scaling\n",
    "\n",
    "Normalization (min-max feautre scaling)\n",
    "###  $X' = \\frac{X-X_{\\min}}{X_{max}-X_{min}}$\n",
    "\n",
    "(Vi tar vårt data, subtraherar minsta värdet. Sedan tar vi dividerat på största och minsta värdet (För varje feature gör vi detta)\n",
    "    Man får ut en matris)\n",
    "\n",
    "\n",
    "###     Feautre standardization\n",
    "*    ### $X' = \\frac{X-\\mu}{\\sigma}$\n",
    "\n",
    "Denna känner vi igen från Z-transformering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scaled_X_train.min()=0.0\n",
      "scaled_X_train.max()=1.0\n",
      "scaled_X_test.min()=0.005964214711729622\n",
      "scaled_X_test.max()=1.1302186878727631\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Skapar en scaler instance(object)\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(X_train)  # Important - use this for training data # Handlar om att transformera/skala eller träna\n",
    "# När man gör fit så anpassar parametrar på ett sätt\n",
    "\n",
    "# Transformerar min data så jag kan utföra min beräkning där jag får ett värde mellan 0-1\n",
    "scaled_X_train = scaler.transform(X_train) #transform är normaliseringsberäkningen  # När vi kör transform är det för vi vill ha mellan 0-1\n",
    "scaled_X_test = scaler.transform(X_test)\n",
    "\n",
    "print(f\"{scaled_X_train.min()=}\")\n",
    "print(f\"{scaled_X_train.max()=}\")\n",
    "print(f\"{scaled_X_test.min()=}\")\n",
    "print(f\"{scaled_X_test.max()=}\")\n",
    "# Note scaled_X_test.min != 0, scaled_X_test.max != 1\n",
    "\n",
    "# 0 <= Scaled_X_train <= 1\n",
    "# .005964214711729622 <= scaled_X_test <= 1.1302186878727631\n",
    "\n",
    "# I outputen så är X_train mellan 0-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.54988164, 0.63709677, 0.52286282],\n",
       "       [0.65843761, 0.96169355, 0.52286282],\n",
       "       [0.98816368, 0.57056452, 0.42644135],\n",
       "       [0.03719986, 0.74395161, 0.44632207],\n",
       "       [0.74264457, 0.98790323, 0.02882704],\n",
       "       [0.25160636, 0.70564516, 0.52087475],\n",
       "       [0.73080825, 0.88508065, 0.26739563],\n",
       "       [0.16672303, 0.23387097, 0.17992048],\n",
       "       [0.74974636, 0.06854839, 0.12723658],\n",
       "       [0.58978695, 0.45362903, 0.31013917],\n",
       "       [0.10415962, 0.49596774, 0.01888668],\n",
       "       [0.18769023, 0.11491935, 0.29224652],\n",
       "       [0.79066622, 0.06854839, 0.83996024],\n",
       "       [0.01589449, 0.60282258, 0.09045726],\n",
       "       [0.46939466, 0.04233871, 0.26143141],\n",
       "       [0.5732161 , 0.15725806, 0.34691849],\n",
       "       [0.02231992, 0.56653226, 0.40854871],\n",
       "       [0.66587758, 0.46975806, 0.13817097],\n",
       "       [0.25228272, 0.40927419, 0.32007952],\n",
       "       [0.80047345, 0.55443548, 0.10636183],\n",
       "       [0.77375719, 0.65120968, 0.73459245],\n",
       "       [0.22691917, 0.73790323, 1.13021869],\n",
       "       [0.12614136, 0.8125    , 0.11530815],\n",
       "       [0.84612783, 0.7358871 , 0.71570577],\n",
       "       [0.23097734, 0.1875    , 0.00596421],\n",
       "       [0.17855935, 0.04032258, 0.20974155],\n",
       "       [0.71964829, 0.86693548, 0.33300199],\n",
       "       [0.4687183 , 0.29233871, 0.09840954],\n",
       "       [0.29252621, 0.23790323, 0.25447316],\n",
       "       [0.02603991, 0.5483871 , 0.01789264],\n",
       "       [0.67331755, 0.05241935, 0.20775348],\n",
       "       [0.2316537 , 0.41330645, 0.17892644],\n",
       "       [0.67027393, 0.99596774, 0.59343936],\n",
       "       [0.05478526, 0.88104839, 0.88568588],\n",
       "       [0.94690565, 0.28024194, 0.36481113],\n",
       "       [0.8031789 , 0.69153226, 0.04970179],\n",
       "       [0.16097396, 0.94758065, 0.08151093],\n",
       "       [0.92323301, 0.58266129, 0.59045726],\n",
       "       [0.39398039, 0.29637097, 0.05069583],\n",
       "       [0.0906324 , 0.03225806, 0.2027833 ],\n",
       "       [0.38992222, 0.15524194, 0.22664016],\n",
       "       [0.59621238, 0.1875    , 0.06063618],\n",
       "       [0.14338857, 0.53830645, 0.34592445],\n",
       "       [0.20831924, 0.25403226, 0.17892644],\n",
       "       [0.75515725, 0.0483871 , 0.15208748],\n",
       "       [0.12681772, 0.07459677, 0.13419483],\n",
       "       [0.23638823, 0.32258065, 0.40258449],\n",
       "       [0.49577274, 0.48185484, 0.18687873],\n",
       "       [0.35136963, 0.11491935, 0.3389662 ],\n",
       "       [0.25566452, 0.55443548, 0.15606362],\n",
       "       [0.26208996, 0.94354839, 0.33996024],\n",
       "       [0.56712885, 0.14314516, 0.12425447],\n",
       "       [0.02705445, 0.9858871 , 0.74254473],\n",
       "       [0.02401082, 0.78427419, 0.5       ],\n",
       "       [0.25600271, 0.01612903, 0.14413519],\n",
       "       [0.43523842, 0.11491935, 0.30815109],\n",
       "       [0.24585729, 0.34274194, 0.12524851],\n",
       "       [0.9773419 , 0.85282258, 0.50596421],\n",
       "       [0.06391613, 0.40524194, 0.16600398],\n",
       "       [0.66587758, 0.07056452, 0.055666  ]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaled_X_test # Ger en numpy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((60, 3), (140, 3))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaled_X_test.shape, scaled_X_train.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters [13.02832938  9.88465985  0.69237469]\n",
      "Intercept 2.741855324852814\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "model_OLS = LinearRegression()\n",
    "model_OLS.fit(scaled_X_train, y_train)  \n",
    "# Fit on training data \n",
    "# Trivia är att scaled är viktig för gradient descent sen.\n",
    "\n",
    "print(f\"Parameters {model_OLS.coef_}\")\n",
    "# beta1, beta2, beta 3\n",
    "print(f\"Intercept {model_OLS.intercept_}\")\n",
    "# Beta 0\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stochastic gradient descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters [11.94828864  8.98630699  1.34761791]\n",
      "Intercept [3.59039629]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDRegressor\n",
    "\n",
    "model_SGD = SGDRegressor(loss=\"squared_error\", max_iter=1000)\n",
    "model_SGD.fit(scaled_X_train, y_train)\n",
    "\n",
    "print(f\"Parameters {model_SGD.coef_}\")\n",
    "print(f\"Intercept {model_SGD.intercept_}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manual prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0.54988164, 0.63709677, 0.52286282]]), 16.9)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_sample_features = scaled_X_test[0].reshape(1, -1)  # Första dimensionen som ett, andra dimensionen ska vi beräkna\n",
    "test_sample_label = y_test.values[0]\n",
    "test_sample_features, test_sample_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 3)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_sample_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16.565396297434837"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_OLS.predict(test_sample_features)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16.590307304079793"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_SGD.predict(test_sample_features)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([163.3,  31.6,  52.9])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.iloc[0].to_numpy() # Dessa är egentligen numrerna vi har från början. Vi måste köra den genom skalaren för att de ska bli samma storlek"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([16.5653963 , 21.18822792, 21.55107058, 10.88923816, 22.20231988])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "\n",
    "# 1. predict on test data\n",
    "y_pred_OLS = model_OLS.predict(scaled_X_test)\n",
    "y_pred_SGD = model_SGD.predict(scaled_X_test)\n",
    "\n",
    "print(f\"{y_pred_OLS[:5]}\")\n",
    "print(f\"{y_pred_SGD[:5]}\")\n",
    "# Plockar de fem första motsvarande för sgd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([16.5903073 , 20.80429161, 21.09920906, 11.3217202 , 21.38017749])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_SGD[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([16.9, 22.4, 21.4,  7.3, 24.7])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test[:5].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mae_OLS=1.511669222454909 \t\t mse_OLS=1.5117 \t rmse_OLS=1.2295\n",
      "mae_SGD=1.5227972082545738 \t\t mse_SGD=1.5228 \t rmse_SGD=1.2340\n"
     ]
    }
   ],
   "source": [
    "mae_OLS = mean_absolute_error(y_test, y_pred_OLS)\n",
    "mae_SGD = mean_absolute_error(y_test, y_pred_SGD)\n",
    "\n",
    "\n",
    "\n",
    "mse_OLS = mean_absolute_error(y_test, y_pred_OLS)\n",
    "mse_SGD = mean_absolute_error(y_test, y_pred_SGD)\n",
    "\n",
    "rmse_OLS = np.sqrt(mse_OLS)\n",
    "rmse_SGD = np.sqrt(mse_SGD)\n",
    "\n",
    "print(f\"{mae_OLS=} \\t\\t {mse_OLS=:.4f} \\t {rmse_OLS=:.4F}\")\n",
    "print(f\"{mae_SGD=} \\t\\t {mse_SGD=:.4f} \\t {rmse_SGD=:.4F}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Machine-Learning-I2BFtoY6",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a90a544548112fd3fa9316a2ef2cee63f5075b890673fd358010aa684e625a09"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
